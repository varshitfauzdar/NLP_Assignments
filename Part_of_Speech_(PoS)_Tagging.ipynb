{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOTKg8By2NiKfO3n0UUN4Jh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varshitfauzdar/NLP_Assignments/blob/main/Part_of_Speech_(PoS)_Tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6ZvyEGThSVN",
        "outputId": "e2aef638-3c30-475a-cec2-733f586e43c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John -> NNP\n",
            "saw -> VBD\n",
            "the -> DT\n",
            "saw -> NN\n",
            "and -> CC\n",
            "decided -> VBD\n",
            "to -> TO\n",
            "take -> VB\n",
            "it -> PRP\n",
            "to -> TO\n",
            "the -> DT\n",
            "table -> NN\n",
            ". -> .\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "# Download once\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "sentence = \"John saw the saw and decided to take it to the table.\"\n",
        "\n",
        "tokens = word_tokenize(sentence)\n",
        "tags = pos_tag(tokens)\n",
        "\n",
        "for word, tag in tags:\n",
        "    print(f\"{word} -> {tag}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "sentence = \"John saw the saw and decided to take it to the table.\"\n",
        "doc = nlp(sentence)\n",
        "\n",
        "for token in doc:\n",
        "    print(f\"{token.text} -> {token.pos_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Stq8aL2ChhMQ",
        "outputId": "6a463701-8918-4a41-9667-f124caec9eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John -> PROPN\n",
            "saw -> VERB\n",
            "the -> DET\n",
            "saw -> NOUN\n",
            "and -> CCONJ\n",
            "decided -> VERB\n",
            "to -> PART\n",
            "take -> VERB\n",
            "it -> PRON\n",
            "to -> ADP\n",
            "the -> DET\n",
            "table -> NOUN\n",
            ". -> PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag import brill, brill_trainer\n",
        "from nltk.tag import UnigramTagger\n",
        "from nltk.corpus import treebank\n",
        "\n",
        "nltk.download('treebank')\n",
        "\n",
        "train_data = treebank.tagged_sents()[:3000]\n",
        "test_data = treebank.tagged_sents()[3000:]\n",
        "\n",
        "initial_tagger = UnigramTagger(train_data)\n",
        "\n",
        "templates = brill.fntbl37()\n",
        "trainer = brill_trainer.BrillTaggerTrainer(initial_tagger, templates)\n",
        "\n",
        "brill_tagger = trainer.train(train_data, max_rules=10)\n",
        "\n",
        "print(\"Accuracy:\", brill_tagger.evaluate(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rbg63IO0iutV",
        "outputId": "45bcbf9b-14ad-4439-aae2-0c17b2e9b60e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "/tmp/ipython-input-1582046228.py:17: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(\"Accuracy:\", brill_tagger.evaluate(test_data))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8662637599827325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag import hmm\n",
        "\n",
        "trainer = hmm.HiddenMarkovModelTrainer()\n",
        "hmm_tagger = trainer.train(train_data)\n",
        "\n",
        "print(\"HMM Accuracy:\", hmm_tagger.evaluate(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBG0XOgBi4Eo",
        "outputId": "4f604efd-fda2-43d3-84cc-8987e2a387e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3532671061.py:6: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(\"HMM Accuracy:\", hmm_tagger.evaluate(test_data))\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/tag/hmm.py:333: RuntimeWarning: overflow encountered in cast\n",
            "  X[i, j] = self._transitions[si].logprob(self._states[j])\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/tag/hmm.py:335: RuntimeWarning: overflow encountered in cast\n",
            "  O[i, k] = self._output_logprob(si, self._symbols[k])\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/tag/hmm.py:331: RuntimeWarning: overflow encountered in cast\n",
            "  P[i] = self._priors.logprob(si)\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/tag/hmm.py:363: RuntimeWarning: overflow encountered in cast\n",
            "  O[i, k] = self._output_logprob(si, self._symbols[k])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HMM Accuracy: 0.36844377293330455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = make_moons(n_samples=1000, noise=0.2)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes=(10,), activation='relu', max_iter=1000)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeuNmp4Mi6vr",
        "outputId": "a176c5a6-c36e-4852-e15e-76f0a48090ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Dummy dataset\n",
        "X = np.random.randn(100, 2)\n",
        "y = (X[:,0] + X[:,1] > 0).astype(int).reshape(-1,1)\n",
        "\n",
        "# Initialize weights\n",
        "W1 = np.random.randn(2, 10)\n",
        "b1 = np.zeros((1,10))\n",
        "W2 = np.random.randn(10,1)\n",
        "b2 = np.zeros((1,1))\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "for epoch in range(1000):\n",
        "\n",
        "    # Forward pass\n",
        "    z1 = X.dot(W1) + b1\n",
        "    a1 = np.maximum(0, z1)  # ReLU\n",
        "\n",
        "    z2 = a1.dot(W2) + b2\n",
        "    a2 = 1 / (1 + np.exp(-z2))  # Sigmoid\n",
        "\n",
        "    # Loss\n",
        "    loss = np.mean((a2 - y)**2)\n",
        "\n",
        "    # Backprop\n",
        "    dz2 = a2 - y\n",
        "    dW2 = a1.T.dot(dz2)\n",
        "    db2 = np.sum(dz2, axis=0)\n",
        "\n",
        "    dz1 = dz2.dot(W2.T)\n",
        "    dz1[z1 <= 0] = 0\n",
        "\n",
        "    dW1 = X.T.dot(dz1)\n",
        "    db1 = np.sum(dz1, axis=0)\n",
        "\n",
        "    # Update\n",
        "    W1 -= lr * dW1\n",
        "    W2 -= lr * dW2\n",
        "    b1 -= lr * db1\n",
        "    b2 -= lr * db2\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(\"Loss:\", loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpDFq6Q-i_PS",
        "outputId": "f0f7bb24-b2d3-4feb-b20b-a728ca213629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.25030205381465653\n",
            "Loss: 0.005918340179956059\n",
            "Loss: 0.0035515098426184915\n",
            "Loss: 0.002527477678344452\n",
            "Loss: 0.001973350729123009\n",
            "Loss: 0.0016174059480168052\n",
            "Loss: 0.0013652275715502562\n",
            "Loss: 0.0011817049200329552\n",
            "Loss: 0.0010350307965574053\n",
            "Loss: 0.000919528375253168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLe5cm84jNtv",
        "outputId": "34699eeb-af1d-483b-bcf7-e58f192e8276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "sentences = [\n",
        "    [\"natural\", \"language\", \"processing\", \"is\", \"fun\"],\n",
        "    [\"word2vec\", \"learns\", \"word\", \"embeddings\"],\n",
        "    [\"nlp\", \"uses\", \"machine\", \"learning\"]\n",
        "]\n",
        "\n",
        "# CBOW\n",
        "cbow_model = Word2Vec(sentences, vector_size=100, window=2, min_count=1, sg=0)\n",
        "print(\"CBOW Similar Words:\", cbow_model.wv.most_similar(\"nlp\"))\n",
        "\n",
        "# Skip-gram\n",
        "skip_model = Word2Vec(sentences, vector_size=100, window=2, min_count=1, sg=1)\n",
        "print(\"Skip-gram Similar Words:\", skip_model.wv.most_similar(\"nlp\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epCOCYw6i_3t",
        "outputId": "c069a5ae-e210-432b-e268-e7de3cc66d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CBOW Similar Words: [('word', 0.13148054480552673), ('fun', 0.07497557997703552), ('machine', 0.06797593086957932), ('learns', 0.0415906086564064), ('language', 0.04130810499191284), ('processing', 0.012979976832866669), ('natural', -0.0092534264549613), ('uses', -0.013514931313693523), ('word2vec', -0.013679763302206993), ('embeddings', -0.044623132795095444)]\n",
            "Skip-gram Similar Words: [('word', 0.13148055970668793), ('fun', 0.07497557997703552), ('machine', 0.06797593086957932), ('learns', 0.041592538356781006), ('language', 0.04130810499191284), ('processing', 0.012979976832866669), ('natural', -0.0092534264549613), ('uses', -0.013514931313693523), ('word2vec', -0.013679763302206993), ('embeddings', -0.044628653675317764)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RXLOWetgjChy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}